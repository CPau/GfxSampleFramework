/*	http://www.reedbeta.com/blog/understanding-bcn-texture-compression-formats/
	http://sjbrown.co.uk/2006/01/19/dxt-compression-techniques/
	http://fileadmin.cs.lth.se/cs/education/edan35/lectures/l8-texcomp.pdf
	http://developer.download.nvidia.com/compute/cuda/1.1-Beta/x86_website/projects/dxtc/doc/cuda_dxtc.pdf
	https://pdfs.semanticscholar.org/presentation/9410/6e86ee70426b81b7f64d392a068c5ebda06a.pdf
	http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.215.7942&rep=rep1&type=pdf
	http://fileadmin.cs.lth.se/graphics/research/papers/gputc2006/thesis.pdf

	\todo
	- Optimize HQ shader.
		- Parallel computation of the covariance matrix: 
			Each of the 6 terms requires looping over the src block and computing the sum of (_src[i][_x] - _avg[_x]) * (_src[i][_y] - _avg[_y]),
			So, make 3 arrays of 16 float for _src[i][x] - _avg[x] (with x = 0,1,2)
			Then either:
				- 6 parallel threads to compute the multiplication/sum part for each of the matrix values. No extra LDS required but threads underutilized).
					Note that this is slower!
				- 6 steps: compute the mul part to an LDS buffer of 16 floats, then sum via parallel reduction. Requires more LDS but better utilizes threads.
				  Could potentially 'interleave' the PR part? More complicated.
			Subsequent steps can't be parallelized! Or would require atomics, so probably not worth it.
	- Systematic error analysis: http://homepages.inf.ed.ac.uk/rbf/CVonline/LOCAL_COPIES/VELDHUIZEN/node18.html
		- Compare vs original, also measure error in an image generated by an offline compression tool.
	- Alpha support + fast path for solid color blocks (see here https://pdfs.semanticscholar.org/presentation/9410/6e86ee70426b81b7f64d392a068c5ebda06a.pdf)
	- 4 blocks at once for better thread utilization (8x8 vs 4x4)?
	- Copy src block to VGPRs?
	- Pack src block as RGB 5:6:5?
	- see https://github.com/OpenGLInsights/OpenGLInsightsCode/blob/master/Chapter%2031%20In-Game%20Video%20Capture%20with%20Real-Time%20Texture%20Compression/bin/shaders/dxt.glsl

	notes:
	- The HQ implementation is basically a copy of stb_dxt but without the refinement step
*/
#include "shaders/def.glsl"

#define ENDPOINT_HQ 1  // use PCA to find endpoints
#define INDEX_HQ    0  // use Euclidean distance to find indices

#define COV_OPTIM 0
#define PARALLEL_REDUCTION 0

uniform sampler2D txSrc;

layout(std430) restrict writeonly buffer _bfDst
{
	uvec2 bfDst[];
};

uint Pack_RGB565(in vec3 _rgb)
{
	uint ret = 0;
	ret = bitfieldInsert(ret, uint(_rgb.r * 31.0), 11, 5);
	ret = bitfieldInsert(ret, uint(_rgb.g * 63.0), 5,  6);
	ret = bitfieldInsert(ret, uint(_rgb.b * 31.0), 0,  5);
	return ret;
}
vec3 Unpack_RGB565(in uint _565)
{
	vec3 ret;
	ret.r = float(bitfieldExtract(_565, 11, 5)) / 31.0;
	ret.g = float(bitfieldExtract(_565, 5,  6)) / 63.0;
	ret.b = float(bitfieldExtract(_565, 0,  5)) / 31.0;
	return ret;
}

shared vec3 s_srcBlock[16];   // raw block texels
shared uint s_dstIndices[16]; // per-texel palette indices

#if COV_OPTIM
	shared vec3  s_covFactors[16];
	shared float s_covMul[16];
	shared float s_covMatrix[6];
#endif

#if PARALLEL_REDUCTION
	shared vec3 s_srcMin[8];
	shared vec3 s_srcMax[8];
	shared vec3 s_srcAvg[8];
#endif

float cov(in int _x, in int _y, in vec3 _avg)
{
	float ret = 0.0;
	for (int i = 0; i < 16; ++i) {
		ret += (s_srcBlock[i][_x] - _avg[_x]) * (s_srcBlock[i][_y] - _avg[_y]);
	}
	ret *= 1.0/16.0;
	return ret;
} 

void main()
{
	#define THREAD_IDX gl_LocalInvocationIndex

 // gather block texels (each thread reads 1 texel)
	ivec2 iuv = ivec2(gl_WorkGroupID.xy * 4 + gl_LocalInvocationID.xy);
	s_srcBlock[THREAD_IDX] = texelFetch(txSrc, iuv, 0).rgb;
	groupMemoryBarrier();

 // find endpoints
	vec3 ep0 = vec3(1.0);
	vec3 ep1 = vec3(0.0);
	#if ENDPOINT_HQ
	 // slow, high-quality: use principal component analysis
	 // http://www.visiondummy.com/2014/04/geometric-interpretation-covariance-matrix/
	 	#if PARALLEL_REDUCTION
		 	if (THREAD_IDX < 8) {
				s_srcMin[THREAD_IDX] = min(s_srcBlock[THREAD_IDX], s_srcBlock[THREAD_IDX + 8]);
				s_srcMax[THREAD_IDX] = max(s_srcBlock[THREAD_IDX], s_srcBlock[THREAD_IDX + 8]);
				s_srcAvg[THREAD_IDX] = s_srcBlock[THREAD_IDX] + s_srcBlock[THREAD_IDX + 8];
				groupMemoryBarrier();
			}
			for (uint i = 4; i > 0; i >>= 1) {
				if (THREAD_IDX < i) {
					s_srcMin[THREAD_IDX] = min(s_srcMin[THREAD_IDX], s_srcMin[THREAD_IDX + i]);
					s_srcMax[THREAD_IDX] = max(s_srcMax[THREAD_IDX], s_srcMax[THREAD_IDX + i]);
					s_srcAvg[THREAD_IDX] = s_srcAvg[THREAD_IDX] + s_srcAvg[THREAD_IDX + i];
				}
				groupMemoryBarrier();
			}
			ep0 = s_srcMin[0];
			ep1 = s_srcMax[0];
			vec3 avg = s_srcAvg[0] / 16.0;
		#else
			vec3 avg = s_srcBlock[0];
	 		ep0 = ep1 = s_srcBlock[0];
			for (int i = 1; i < 16; ++i) {
				ep0  = min(ep0, s_srcBlock[i]);
				ep1  = max(ep1, s_srcBlock[i]);
				avg += s_srcBlock[i];
			}
			avg *= 1.0/16.0;
		#endif

	 // generate covariance matrix
		#if COV_OPTIM
			s_covFactors[THREAD_IDX] = s_srcBlock[THREAD_IDX] - avg;

			#if 0
		 	 // use 6 threads to generate the matrix elements
			 // \todo this is slower than the unoptimized version, maybe due to bank conflicts?
			 // you're also not removing the loop, only some of the computation inside it, if you accept to do the subtraction in the loop you could avoid a memory barrier.
				const uvec2 covIndices[6] = { 
					uvec2(0, 0),
					uvec2(0, 1),
					uvec2(0, 2),
					uvec2(1, 1),
					uvec2(1, 2),
					uvec2(2, 2)
					}; 
				if (THREAD_IDX < 6) {
					groupMemoryBarrier(); // only these threads need to wait for s_coFactors
					float ret = 0.0;
					uvec2 ci = covIndices[THREAD_IDX];
					for (int i = 0; i < 16; ++i) {
						ret += s_covFactors[i][ci.x] * s_covFactors[i][ci.y];
					}
					s_covMatrix[THREAD_IDX] = ret * 1.0/16.0;
				}
				groupMemoryBarrier();
				
				mat3  C = mat3(
					s_covMatrix[0], s_covMatrix[1], s_covMatrix[2],
					s_covMatrix[1], s_covMatrix[3], s_covMatrix[4],
					s_covMatrix[2], s_covMatrix[4], s_covMatrix[5]
					);
			#else
			 // compute the values to sum
				s_covMul[THREAD_IDX]  = s_covFactors[THREAD_IDX][0] * s_covFactors[THREAD_IDX][0];
				groupMemoryBarrier();
				s_covMul[THREAD_IDX] += s_covFactors[THREAD_IDX][0] * s_covFactors[THREAD_IDX][1];
				groupMemoryBarrier();
				s_covMul[THREAD_IDX] += s_covFactors[THREAD_IDX][0] * s_covFactors[THREAD_IDX][2];
				groupMemoryBarrier();
				s_covMul[THREAD_IDX] += s_covFactors[THREAD_IDX][1] * s_covFactors[THREAD_IDX][1];
				groupMemoryBarrier();
				s_covMul[THREAD_IDX] += s_covFactors[THREAD_IDX][1] * s_covFactors[THREAD_IDX][2];
				groupMemoryBarrier();
				s_covMul[THREAD_IDX] += s_covFactors[THREAD_IDX][2] * s_covFactors[THREAD_IDX][2];
				groupMemoryBarrier();

			 // sum
				#if PARALLEL_REDUCTION
				#else
					float sum = s_covMul[0];
					for (int i = 1; i < 16; ++i) {
						sum += s_covMul[i];
					}
					s_covMatrix[THREAD_IDX] = ret * 1.0/16.0;
				#endif
				groupMemoryBarrier();
				
				mat3 C = mat3(
					s_covMatrix[0], s_covMatrix[1], s_covMatrix[2],
					s_covMatrix[1], s_covMatrix[3], s_covMatrix[4],
					s_covMatrix[2], s_covMatrix[4], s_covMatrix[5]
					);
			#endif
		
		#else
			float cRR = cov(0, 0, avg);
			float cRG = cov(0, 1, avg);
			float cRB = cov(0, 2, avg);
			float cGG = cov(1, 1, avg);
			float cGB = cov(1, 2, avg);
			float cBB = cov(2, 2, avg);
			mat3  C = mat3(
				cRR, cRG, cRB,
				cRG, cGG, cGB,
				cRB, cGB, cBB
				);
		#endif

	 // find endpoints
		vec3 vf = ep1 - ep0;
		for (int i = 0; i < 16; ++i) { // \TODO this doesn't seem to affect the quality much?
			float x = dot(vf, C[0]);
			float y = dot(vf, C[1]);
			float z = dot(vf, C[2]);
			vf = vec3(x, y, z);
		}
		float vflen = length2(vf);
		if (vflen > 1e-4) {
			vf /= sqrt(vflen);
		}

		float mind, maxd;
		mind = maxd = dot(vf, s_srcBlock[0]);
		for (int i = 1; i < 16; ++i) {
			float d = dot(vf, s_srcBlock[i]);
			if (d < mind) {
				ep0 = s_srcBlock[i];
				mind = d;
			}
			if (d > maxd) {
				ep1 = s_srcBlock[i];
				maxd = d;
			}
		}
	#else
	 // fast, low-quality: find the color space bounding box, endpoints are min/max
		#if PARALLEL_REDUCTION
			if (THREAD_IDX < 8) {
				s_srcMin[THREAD_IDX] = min(s_srcBlock[THREAD_IDX], s_srcBlock[THREAD_IDX + 8]);
				s_srcMax[THREAD_IDX] = max(s_srcBlock[THREAD_IDX], s_srcBlock[THREAD_IDX + 8]);
				groupMemoryBarrier();
			}
			for (uint i = 4; i > 0; i >>= 1) {
				if (THREAD_IDX < i) {
					s_srcMin[THREAD_IDX] = min(s_srcMin[THREAD_IDX], s_srcMin[THREAD_IDX + i]);
					s_srcMax[THREAD_IDX] = max(s_srcMax[THREAD_IDX], s_srcMax[THREAD_IDX + i]);
				}
				groupMemoryBarrier();
			}
			ep0 = s_srcMin[0];
			ep1 = s_srcMax[0];
		#else
	 		ep0 = ep1 = s_srcBlock[0];
			for (int i = 1; i < 16; ++i) {
				ep0 = min(ep0, s_srcBlock[i]);
				ep1 = max(ep1, s_srcBlock[i]);
			}
		#endif
	#endif
	
 // export endpoints (type 1)
	uvec2 dst;
	uint ep0i = Pack_RGB565(ep0);	
	uint ep1i = Pack_RGB565(ep1);
	dst[0] = 0;
	if (ENDPOINT_HQ == 1 && ep0i > ep1i) {
		dst[0] = bitfieldInsert(dst[0], ep0i, 0,  16);
		dst[0] = bitfieldInsert(dst[0], ep1i, 16, 16);
		vec3 tmp = ep1;
		ep1 = ep0;
		ep0 = tmp;
	} else {
		dst[0] = bitfieldInsert(dst[0], ep1i, 0,  16);
		dst[0] = bitfieldInsert(dst[0], ep0i, 16, 16);
	}

 // find palette indices per texel
	#if INDEX_HQ
	{
	 // square euclidean distance
		vec3 palette[4];
		palette[0] = ep1;
		palette[1] = ep0;
		palette[2] = 2.0/3.0 * palette[0] + 1.0/3.0 * palette[1];
		palette[3] = 1.0/3.0 * palette[0] + 2.0/3.0 * palette[1];
		#if 1
		 // pack/unpack the palette values = quantize palette so that texel indices are generated from the final result
		 // \todo it's not clear that this significantly improves the quality
			for (int i = 0; i < 4; ++i) {
				palette[i] = Unpack_RGB565(Pack_RGB565(palette[i]));
			}
		#endif

		int idx = 0;
		float minErr = 999.0;
		for (int i = 0; i < 4; ++i) {
			float err = length2(s_srcBlock[THREAD_IDX] - palette[i]);
			if (err < minErr) {
				minErr = err;
				idx = i;
			}
			s_dstIndices[THREAD_IDX] = idx;
		}
	}
	#else
	{
	 // project onto (ep1 - ep0)
		vec3 d = ep1 - ep0;
		float dlen = length(d);
		d /= dlen;
	 	vec3 src = s_srcBlock[THREAD_IDX];
		float idx = dot(src - ep0, d) / dlen;

	 // round to nearest palette index
		idx = round(saturate(idx) * 3.0);
		const uvec4 idxMap = uvec4(1, 3, 2, 0);
		s_dstIndices[THREAD_IDX] = idxMap[uint(idx)];
	}
	#endif
	groupMemoryBarrier();

 // final block export
	if (THREAD_IDX == 0) {
	 // pack palette indices
		dst[1] = 0;
		for (int i = 0; i < 16; ++i) {
			dst[1] = bitfieldInsert(dst[1], s_dstIndices[i], (i * 2), 2);
		}
	
	 // write block data
		bfDst[gl_WorkGroupID.y * gl_NumWorkGroups.x + gl_WorkGroupID.x] = dst;
	}
}
